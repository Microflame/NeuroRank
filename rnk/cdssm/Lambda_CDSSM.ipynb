{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(path, dtype=np.float):\n",
    "    res = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            res.append(line.split())\n",
    "    return np.array(res, dtype=dtype)\n",
    "\n",
    "def load_txt_fast(path, shape, dtype=np.float):\n",
    "    res = np.empty(shape, dtype=dtype)\n",
    "    with open(path) as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            res[i] = line.split()\n",
    "            i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NDCG\n",
    "\n",
    "def calc_dcg(m, p, k=5):\n",
    "    assert len(m) == len(p)\n",
    "    order = np.argsort(-p)[:k]\n",
    "    dcg = 0\n",
    "    for i in order:\n",
    "        dcg += (2 ** m[i] - 1) / (np.log2(i + 2))\n",
    "    return dcg\n",
    "\n",
    "def calc_ndcg(marks, preds, groups):\n",
    "    ndcgs = []\n",
    "    \n",
    "    start = 0\n",
    "    cur_group = groups[0]\n",
    "    for i in range(len(marks)):\n",
    "        if groups[i] != cur_group:\n",
    "            m = marks[start:i]\n",
    "            p = preds[start:i]\n",
    "            ndcg = calc_dcg(m, p) / (calc_dcg(m, m) + 1e-5)\n",
    "            ndcgs.append(ndcg)\n",
    "            start = i\n",
    "            cur_group = groups[i]\n",
    "    m = marks[start:]\n",
    "    p = preds[start:]\n",
    "    ndcg = calc_dcg(m, p) / (calc_dcg(m, m) + 1e-5)\n",
    "    ndcgs.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuw_words = 30\n",
    "num_ngrams = 20\n",
    "phrase_size = nuw_words * num_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = load_txt_fast('./data/processed_tr.tsv', (161626, 2 * phrase_size), dtype=np.int)\n",
    "X_tr = X_tr.reshape(-1, 2, nuw_words, num_ngrams)\n",
    "\n",
    "y_tr = load_txt_fast('../../data/raw/m_train.tsv', (161626, 1)).ravel()\n",
    "groups_tr = load_txt_fast('../../data/raw/groups.tr.tsv', (161626, 1), dtype=np.int).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = load_txt_fast('./data/processed_te.tsv', (40101, 2 * phrase_size), dtype=np.int)\n",
    "X_te = X_te.reshape(-1, 2, nuw_words, num_ngrams)\n",
    "\n",
    "y_te = load_txt_fast('../../data/raw/m_test.tsv', (40101, 1), dtype=np.int).ravel()\n",
    "groups_te = load_txt_fast('../../data/raw/groups.te.tsv', (40101, 1), dtype=np.int).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaGroup:\n",
    "    def __init__(self, marks, begin, end):\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "        marks = marks[begin:end]\n",
    "        sg = defaultdict(list)\n",
    "        for i, m in enumerate(marks):\n",
    "            sg[m].append(i)\n",
    "        self.subgroups = list(map(lambda x:x[1], sorted(sg.items(), key=lambda x:-x[0])))\n",
    "        \n",
    "class LambdaDssmDataloader:\n",
    "    def __init__(self, marks, data, groups, shuffle=False):\n",
    "        assert len(marks) == len(data)\n",
    "        assert len(marks) == len(groups)\n",
    "        \n",
    "        self.marks = marks\n",
    "        self.data = data\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        cur_group = groups[0]\n",
    "        self.groups = []\n",
    "        begin = 0\n",
    "        for i in range(len(groups)):\n",
    "            if groups[i] != cur_group:\n",
    "                cur_group = groups[i]\n",
    "                self.groups.append(LambdaGroup(marks, begin, i))\n",
    "                begin = i\n",
    "        self.groups.append(LambdaGroup(marks, begin, len(groups)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        g = self.groups[idx]\n",
    "        begin = g.begin\n",
    "        end = g.end\n",
    "        return self.marks[begin:end], self.data[begin:end], g.subgroups\n",
    "    \n",
    "    def __iter__(self):\n",
    "        order = np.arange(len(self))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(order)\n",
    "        for i in order:\n",
    "            yield self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = LambdaDssmDataloader(y_tr, X_tr, groups_tr, True)\n",
    "train_dataloader_lin = LambdaDssmDataloader(y_tr, X_tr, groups_tr, False)\n",
    "\n",
    "test_dataloader = LambdaDssmDataloader(y_te, X_te, groups_te, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ndcg(model, dl, a_y, a_g):\n",
    "    preds = np.empty(len(a_y))\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for targets, qd_pairs, _ in dl:\n",
    "            qd_pairs = Variable(torch.tensor(qd_pairs)).cuda()\n",
    "            pred = model(qd_pairs).cpu().data.numpy()\n",
    "            preds[i:i+len(pred)] = pred\n",
    "            i += len(pred)\n",
    "    \n",
    "    return calc_ndcg(a_y, preds, a_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lambdas(s, subgroups):\n",
    "    lambdas = np.zeros(len(s), dtype=np.float32)\n",
    "    for best_sg in range(len(subgroups) - 1):\n",
    "        for worse_sg in range(best_sg + 1, len(subgroups)):\n",
    "            for i in subgroups[best_sg]:\n",
    "                for j in subgroups[worse_sg]:\n",
    "                    delta = np.clip(s[i] - s[j], -30, 30)\n",
    "                    lmb = - 1.0 / (1.0 + np.exp(delta))\n",
    "                    lambdas[i] += lmb\n",
    "                    lambdas[j] -= lmb\n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSSM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CDSSM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(13678, 128, sparse=True)\n",
    "        self.conv = nn.Conv1d(128, 128, 3, padding=1)\n",
    "        \n",
    "        self.NL = nn.functional.elu\n",
    "        \n",
    "    def params(self):\n",
    "        par = [self.conv.parameters()]\n",
    "        for ps in par:\n",
    "            for p in ps:\n",
    "                yield p\n",
    "                \n",
    "    def sparse_params(self):\n",
    "        par = [self.embedding.parameters()]\n",
    "        for ps in par:\n",
    "            for p in ps:\n",
    "                yield p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x, 3)\n",
    "        x = x.view(-1, 60, 128).permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 1).view(-1, 2, 30, 128)\n",
    "        x = torch.max(x, 2)[0]\n",
    "\n",
    "        prod = torch.prod(x, 1)\n",
    "        dot_prod = torch.mean(prod, 1)\n",
    "        pred = dot_prod\n",
    "        \n",
    "        return pred.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CDSSM().cuda()\n",
    "opt = torch.optim.Adam(model.params(), 0.01)\n",
    "sparse_opt = torch.optim.SparseAdam(model.sparse_params(), 0.01)\n",
    "# sparse_opt = torch.optim.SGD(model.parameters(), 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, 999999999, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 10]\t0.549\t0.490\n",
      "[2 / 10]\t0.637\t0.499\n",
      "[3 / 10]\t0.710\t0.485\n",
      "[4 / 10]\t0.760\t0.468\n",
      "[5 / 10]\t0.785\t0.474\n",
      "[6 / 10]\t0.813\t0.471\n",
      "[7 / 10]\t0.801\t0.450\n",
      "[8 / 10]\t0.824\t0.451\n",
      "[9 / 10]\t0.858\t0.454\n",
      "[10 / 10]\t0.844\t0.458\n",
      "CPU times: user 10min 2s, sys: 2min 30s, total: 12min 32s\n",
      "Wall time: 12min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    cnt = 20000\n",
    "    for marks, qd_pairs, subgroups in train_dataloader:\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break\n",
    "        qd_pairs = Variable(torch.tensor(qd_pairs)).cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        s = model(qd_pairs)\n",
    "#         break\n",
    "        lambdas = calc_lambdas(s.data.cpu().numpy(), subgroups)\n",
    "        \n",
    "#         lambdas = torch.tensor(lambdas).cuda()\n",
    "        s.backward(lambdas)\n",
    "        opt.step()\n",
    "        sparse_opt.step()\n",
    "    train_ndcg = eval_ndcg(model, train_dataloader_lin, y_tr, groups_tr)\n",
    "    test_ndcg = eval_ndcg(model, test_dataloader, y_te, groups_te)\n",
    "    scheduler.step()\n",
    "    print('[%d / %d]\\t%.3lf\\t%.3lf' % (e, epochs, train_ndcg, test_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 10]\t0.429\t0.446\n",
      "[2 / 10]\t0.454\t0.455\n",
      "[3 / 10]\t0.480\t0.470\n",
      "[4 / 10]\t0.504\t0.477\n",
      "[5 / 10]\t0.516\t0.476\n",
      "[6 / 10]\t0.526\t0.476\n",
      "[7 / 10]\t0.532\t0.473\n",
      "[8 / 10]\t0.539\t0.478\n",
      "[9 / 10]\t0.547\t0.476\n",
      "[10 / 10]\t0.550\t0.481\n",
      "CPU times: user 9min 28s, sys: 2min 20s, total: 11min 49s\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Disabled convolutions\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    cnt = 20000\n",
    "    for marks, qd_pairs, subgroups in train_dataloader:\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break\n",
    "        qd_pairs = Variable(torch.tensor(qd_pairs)).cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        s = model(qd_pairs)\n",
    "#         break\n",
    "        lambdas = calc_lambdas(s.data.cpu().numpy(), subgroups)\n",
    "        \n",
    "        lambdas = torch.tensor(lambdas).cuda()\n",
    "        s.backward(lambdas)\n",
    "        opt.step()\n",
    "        sparse_opt.step()\n",
    "    train_ndcg = eval_ndcg(model, train_dataloader_lin, y_tr, groups_tr)\n",
    "    test_ndcg = eval_ndcg(model, test_dataloader, y_te, groups_te)\n",
    "    scheduler.step()\n",
    "    print('[%d / %d]\\t%.3lf\\t%.3lf' % (e, epochs, train_ndcg, test_ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 108 ms, total: 2.14 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = np.empty(len(y_te))\n",
    "\n",
    "model.cuda()\n",
    "i = 0\n",
    "for qd_pairs, targets in test_dataloader:\n",
    "    qd_pairs = Variable(qd_pairs).cuda()\n",
    "    targets = Variable(targets).cuda()\n",
    "    pred = model(qd_pairs).cpu().data.numpy()\n",
    "    preds[i:i+len(pred)] = pred\n",
    "    i += len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4653389935005265"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ndcg(y_te, preds, groups_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./data/pred.tsv', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
